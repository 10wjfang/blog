---
layout: post
title: 【存储】HDFS的数据操作（四）
date: 2018-9-11 21:21:33
catalog: true
tags:
    - 大数据
    - Hadoop
    - HDFS
---

## HDFS架构

![img](../../../../img/in-post/post_bigdata/13.jpg)

## HDFS工作原理

- 文件是被切块存储在若干台`datanode`服务器上
- hdfs提供了一个统一的目录树来定位hdfs中的文件，客户端访问文件时只要指定目录树的路径即可，不用关心文件的具体物理位置
- 每一个文件的每一个切块，在hdfs集群中都可以保存多个备份（默认３份），在`hdfs-site.xml`中，`dfs.replication`的value的数量就是备份的数量
- namenode，它维护了一个hdfs的目录树及hdfs目录结构与文件真实存储位置的映射关系（元数据）
- datanode服务进程专门负责接收和管理＂文件块＂－block,默认大小为128M(可配置dfs.blocksize)

## HDFS shell命令

**hdfs dfs 与 hadoop fs 效果一样**

|使用格式|含义|例子|
|:--:|:--:|:--:|
|-ls <路径>|查看指定路径的当前目录结构|-ls /|
|-lsr <路径>|递归查看指定路径的目录结构|-lsr /|
|-du <路径>|统计目录下个文件大小|-du /|
|-dus <路径>|汇总统计目录下文件(夹)大小|-dus /|
|-count [-q] <路径>|统计文件(夹)数量|-count /|
|-mv <源路径> <目的路径>|移动|-mv /test1 /test2|
|-cp <源路径> <目的路径>|复制|-cp /test1 /test2|
|-rm [-skipTrash] <路径>|删除文件/空白文件夹|-rm /test1|
|-rmr [-skipTrash] <路径>|递归删除|-rm /test1|
|-put <多个linux上的文件> <hdfs路径>|上传文件|-put test.txt /|
|-cat <hdfs路径>|查看文件内容|-cat /test.txt|
|-mkdir <hdfs路径>|创建空白文件夹|-mkdir /output|
|-help [命令选项]|帮助|-help ls|
