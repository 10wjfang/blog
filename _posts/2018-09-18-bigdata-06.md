---
layout: post
title: 【存储】HBASE入门及安装部署（七）
date: 2018-9-18 16:28:27
catalog: true
tags:
    - 大数据
    - Hadoop
    - HBase
    - Zookeeper
---

## HBase介绍

HBase是Hadoop Database的简称，是一个分布式的、面向列的开源数据库。使用HBase在HDFS读取消费/随机访问数据（**随机存取**）。

- 利用Hadoop HDFS作为其文件存储系统
- 利用Hadoop MapReduce来处理HBase中的海量数据
- 利用Zookeeper作为协同服务
- 高可靠、高性能、面向列、可伸缩

## HBase架构

HBase 需要运行在 HDFS 之上，以 HDFS 作为其基础的存储设施。HBase 上层提供了访问的数据的 Java API 层，供应用访问存储在 HBase 的数据。在 HBase 的集群中主要由 Master 和 Region Server 组成，以及 Zookeeper，具体模块如下图所示：
![img](../../../../img/in-post/post_bigdata/17.png)

- Master
HBase Master用于协调多个Region Server，侦测各个RegionServer之间的状态，并平衡RegionServer之间的负载。HBaseMaster还有一个职责就是负责分配Region给RegionServer。HBase允许多个Master节点共存，但是这需要Zookeeper的帮助。不过当多个Master节点共存时，只有一个Master是提供服务的，其他的Master节点处于待命的状态。当正在工作的Master节点宕机时，其他的Master则会接管HBase的集群。

- Region Server
对于一个RegionServer而言，其包括了多个Region。RegionServer的作用只是管理表格，以及实现读写操作。Client直接连接RegionServer，并通信获取HBase中的数据。对于Region而言，则是真实存放HBase数据的地方，也就说Region是HBase可用性和分布式的基本单位。如果当一个表格很大，并由多个CF组成时，那么表的数据将存放在多个Region之间，并且在每个Region中会关联多个存储的单元（Store）。

- Zookeeper
对于 HBase 而言，Zookeeper的作用是至关重要的。首先Zookeeper是作为HBase Master的HA解决方案。也就是说，是Zookeeper保证了至少有一个HBase Master 处于运行状态。并且Zookeeper负责Region和Region Server的注册。其实Zookeeper发展到目前为止，已经成为了分布式大数据框架中容错性的标准框架。不光是HBase，几乎所有的分布式大数据相关的开源框架，都依赖于Zookeeper实现HA。

## HBase的存储机制

#### 物理模型

![img](../../../../img/in-post/post_bigdata/18.png)

HRegionServer是HBase中最主要的组件，负责table数据的实际读写，管理Region。在分布式集群中，HRegionServer一般跟DataNode在同一个节点上，目的是实现数据的本地性，提高读写效率。

- Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上。
- 每个Region包含着多个Store对象。每个Store包含一个MemStore或若干StoreFile，StoreFile包含一个或多个HFile。MemStore存放在内存中，StoreFile存储在HDFS上。

#### 逻辑视图

![img](../../../../img/in-post/post_bigdata/19.png)

基本概念：

- RowKey：是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要；
- Column Family：列族，拥有一个名称(string)，包含一个或者多个相关列；
- Column：属于某一个columnfamily，familyName:columnName，每条记录可动态添加；
- Timestamp：类型为Long，默认值是系统时间戳，可由用户自定义；一个单元格的不同版本的值按照时间戳降序排列在一起，在读取的时候优先取最新的值。
- Cell：单元格，即：<key, columnfamily, columnname, timestamp>

**客户端首次读写的流程：**
1. 客户端首先从zookeeper中得到META table的位置，根据META table的存储位置得到具体的RegionServer是哪台
2. 询问具体的RegionServer

**写流程：**
1. 首先写入WAL日志，以防crash。
2. 紧接着写入Memstore，即写缓存。由于是内存写入，速度较快。
3. 立马返回客户端表示写入完毕。
4. 当Memstore满时，从Memstore刷新到HFile，磁盘的顺序写速度非常快，并记录下最后一次最高的sequence号。这样系统能知道哪些记录已经持久化，哪些没有。

**读流程：**
1. 首先到读缓存BlockCache中查找可能被缓存的数据
2. 如果未找到，到写缓存查找已提交但是未落HFile的数据
3. 如果还未找到， 到HFile中继续查找数据

## 实验环境

虚拟机：`3台`
Hadoop版本：`2.9.1`
Java版本：`1.8`
HBase版本：`1.4.7`
ZooKeeper：`3.4.12`

## HBase安装部署

#### 安装前准备

1、准备不少于3个节点的集群，这里是Hadoop-Master、Hadoop-Slave、Hadoop-Slave2。

2、 各服务器之间系统时间保持一致
先设置时区为亚洲上海：
```sh
sudo cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
```
切换到root，每小时从时间服务器上同步时间：
```sh
crontab -e
0 1 * * * /usr/sbin/ntpdate cn.pool.ntp.org
```

#### 下载

到`http://mirror.bit.edu.cn/apache/hadoop/common/`下载稳定版HBase，下载完成后上传到Hadoop-Master节点，解压。

到`http://mirror.bit.edu.cn/apache/zookeeper/stable/`下载Zookeeper，下载完成后上传到Hadoop-Master节点，解压。

#### 安装Zookeeper

1、配置zoo.cfg属性文件，文件在`~/zookeeper-3.4.12/conf`目录，重命名zoo_sample.cfg
- 修改dataDir目录，`dataDir=/home/fwj/zookeeper-3.4.12/data
`
- 配置服务器 service.N =YYY:A:B

**说明：**
N：代表服务器编号（也就是myid里面的值）
YYY：服务器地址
A：表示 Flower 跟 Leader的通信端口，简称服务端内部通信的端口（默认2888）
B：表示 是选举端口（默认是3888）
```
server.1=hadoop-master:2888:3888
server.2=hadoop-slave:2888:3888
server.3=hadoop-slave2:2888:3888
```

2、创建`data`文件夹，在该目录下创建`myid`文件，内容为`1`

3、修改环境变量
```sh
export ZOOKEEPER_HOME=/home/fwj/zookeeper-3.4.12
export PATH=$ZOOKEEPER_HOME/bin:$PATH
```

4、拷贝zookeeper-3.4.12到其它节点

```sh
scp -r zookeeper-3.4.12 fwj@hadoop-slave:~/
scp -r zookeeper-3.4.12 fwj@hadoop-slave2:~/
```
修改Hadoop-Slave的zookeeper-3.4.12的data目录下的myid为2，修改Hadoop-Slave的zookeeper-3.4.12的data目录下的myid为3。

#### 启动

在3个节点分别运行以下命令：
```sh
zkServer.sh start
```
查看状态：
```sh
zkServer sh status
```

## 安装HBase

#### 配置HBase

1、修改环境变量hbase-env.sh

```
export JAVA_HOME=/usr/java/jdk1.8.0_181
export HBASE_MANAGES_ZK=false
```

2、修改配置文件hbase-site.xml
```xml
<configuration>
    <property>
        <name>hbase.rootdir</name>
        <value>hdfs://hadoop-master:9000/hbase</value>
    </property>
    <property>
        <name>hbase.cluster.distributed</name>
        <value>true</value>
    </property>
    <property>
        <name>hbase.zookeeper.quorum</name>
        <value>hadoop-master:2181,hadoop-slave:2181,hadoop-slave2:2181</value>
    </property>
</configuration>
```

3、设置regionservers
```
hadoop-slave
hadoop-slave2
```

4、设置环境变量
```
export HBASE_HOME=/home/fwj/hbase-1.4.7
export PATH=$HBASE_HOME/bin:$PATH
export HADOOP_CLASSPATH=$HBASE_HOME/lib/*
```

5、复制到其它节点
```sh
scp -r hbase-1.4.7 fwj@hadoop-slave:~/
scp -r hbase-1.4.7 fwj@hadoop-slave2:~/
```

#### 启动并验证

1、在Hadoop-Master上运行`start-hbase.sh`

2、访问`http://hadoop-master:60010`

到这里HBase就安装完成。

## 参考

[HBase官方文档](http://hbase.apache.org/book.html)

[Hadoop相关知识整理系列之一：HBase基本架构及原理](http://www.cnblogs.com/csyuan/p/6543018.html)