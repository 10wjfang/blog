---
layout: post
title: 【架构】Hadoop集群添加新节点（六）
date: 2018-9-18 14:29:56
catalog: true
tags:
    - 大数据
    - Hadoop
---

## 目的

添加Hadoop-Slave2到集群。

| 主机 | IP |
| :---: | :---: |
|Hadoop-Master | 192.168.241.140 |
|Hadoop-Slave | 192.168.241.141 |
|Hadoop-Slave2 | 192.168.241.142 |

## 修改Hadoop-Master配置文件

#### 修改slaves文件

`/home/fwj/hadoop-2.9.1/etc/hadoop/slaves`增加新节点：
```txt
hadoop-slave
hadoop-slave2
```

#### 修改hosts文件

`/etc/hosts`增加ip与hostname的映射：
```txt
192.168.241.140 Hadoop-Master
192.168.241.141 Hadoop-Slave
192.168.241.142 Hadoop-Slave2
```

## 拷贝配置文件到Hadoop-Slave

拷贝slaves文件：
```sh
scp /home/fwj/hadoop-2.9.1/etc/hadoop/slaves fwj@Hadoop-Slave:~/hadoop-2.9.1/etc/hadoop/slaves
```

Hadoop-Slave的`/etc/hosts`增加ip与hostname的映射：
```txt
192.168.241.140 Hadoop-Master
192.168.241.141 Hadoop-Slave
192.168.241.142 Hadoop-Slave2
```

## 克隆Hadoop-Master到Hadoop-Slave2

克隆成功后启动Hadoop-Slave2，配置IP地址和hostname。

/etc/network/interfaces文件：
```
auto eth0
iface eth0 inet static
address 192.168.241.142
netmask 255.255.255.0
gateway 192.168.241.2
```

/etc/hostname文件：
```
Hadoop-Slave2
```

重启服务器。

## 配置免密登录

1、在Hadoop-Master节点上执行`ssh-keygen -t rsa -P ''`

2、把id_rsa.pub追加到授权的key里面`cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys`

3、修改`/etc/ssh/sshd_config`，检查下面内容前面的`#`是否有去掉
```
RSAAuthentication yes # 启用 RSA 认证
PubkeyAuthentication yes # 启用公钥私钥配对认证方式
AuthorizedKeysFile  %h/.ssh/authorized_keys # 公钥文件路径
```

4、重启ssh服务，`service ssh restart`

5、复制公钥到所有的Slave
```sh
ssh-copy-id fwj@hadoop-slave
ssh-copy-id fwj@hadoop-slave2
```

## Hadoop-Master启动Hadoop

```sh
start-all.sh
```

## 验证是否成功

```sh
fwj@Hadoop-Master:~$ hdfs dfsadmin -report
```

输出：
```
Configured Capacity: 19810402304 (18.45 GB)
Present Capacity: 12403527680 (11.55 GB)
DFS Remaining: 12402741248 (11.55 GB)
DFS Used: 786432 (768 KB)
DFS Used%: 0.01%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0
Pending deletion blocks: 0

-------------------------------------------------
Live datanodes (2):

Name: 192.168.241.141:50010 (Hadoop-Slave)
Hostname: Hadoop-Slave
Decommission Status : Normal
Configured Capacity: 9905201152 (9.22 GB)
DFS Used: 757760 (740 KB)
Non DFS Used: 2625122304 (2.44 GB)
DFS Remaining: 6752571392 (6.29 GB)
DFS Used%: 0.01%
DFS Remaining%: 68.17%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Tue Sep 18 15:29:36 CST 2018
Last Block Report: Tue Sep 18 15:02:39 CST 2018


Name: 192.168.241.142:50010 (Hadoop-Slave2)
Hostname: Hadoop-Slave2
Decommission Status : Normal
Configured Capacity: 9905201152 (9.22 GB)
DFS Used: 28672 (28 KB)
Non DFS Used: 3728252928 (3.47 GB)
DFS Remaining: 5650169856 (5.26 GB)
DFS Used%: 0.00%
DFS Remaining%: 57.04%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Tue Sep 18 15:29:35 CST 2018
Last Block Report: Tue Sep 18 15:10:38 CST 2018
```

## 参考

- [hadoop集群添加新节点](https://www.cnblogs.com/fefjay/p/6048269.html)

- [一步步教你Hadoop多节点集群安装配置](https://blog.csdn.net/u011692203/article/details/46898293)