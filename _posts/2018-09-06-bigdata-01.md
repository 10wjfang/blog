---
layout: post
title: 【架构】手把手安装Hadoop集群（二）
date: 2018-9-6 21:08:29
catalog: true
tags:
    - 大数据
    - Hadoop
---

## Hadoop由来

最先受到由 Google Lab 开发的 Map/Reduce 和 Google File System(GFS) 的启发，2011年发布第一版，截止目前为止，稳定版到3.0.0。

## Hadoop简介

- Hadoop是
  - Apache开源软件基金会开发的
  - 运行于大规模普通服务器上的
  - 大数据存储、计算、分析的
  - 分布式存储系统和分布式运算框架

- Hadoop2.0由三部分组成
  - 分布式文件系统HDFS
  - 资源分配系统Yarn
  - 分布式运算框架MapReduce

![img](../../../../img/in-post/post_bigdata/4.jpg)

## Hadoop的地位

![img](../../../../img/in-post/post_bigdata/3.jpg)

## 了解HDFS

![img](../../../../img/in-post/post_bigdata/5.png)

#### Client：客户端

- 与NameNode交互，获取文件的位置信息
- 与DataNode交互，读写数据
- 提供一些命令管理和访问HDFS

#### NameNode：充当Master

- 管理 HDFS 的名称空间
- 管理数据块（Block）映射信息
- 配置副本策略
- 处理客户端读写请求

#### DataNode：充当Slave

- 存储实际的数据块
- 执行数据块的读/写操作

## 了解Yarn

Yet Another Resource Negotiator（另一种资源协调者），是一种新的Hadoop**资源管理器，它是一个通用资源管理系统，可为上层应用提供统一的资源管理和调度**。

![img](../../../../img/in-post/post_bigdata/6.png)

- ResurceManager(RM)：一个纯粹的调度器，专门负责集群中可用资源的分配和管理。
- Container ：分配给具体应用的资源抽象表现形式，包括内存、cpu、disk
- NodeManager(NM) ：负责节点本地资源的管理，包括启动应用程序的Container，监控它们的资源使用情况，并报告给RM
- App Master (ApplicationMaster(AM))：特定框架库的一个实例，负责有RM协商资源，并和NM协调工作来执行和监控Container以及它们的资源消耗。AM也是以一个的Container身份运行。
- 客户端（Client）：是集群中一个能向RM提交应用的实例，并且指定了执行应用所需要的AM类型

## 开始搭建

#### 运行环境

系统：`Ubuntu 14.04`

JDK版本：`1.8.0`

Hadoop：`2.9.1`

| 主机 | IP |
| :---: | :---: |
|Hadoop-Master | 192.168.241.140 |
|Hadoop-Slave | 192.168.241.141 |

#### 配置hosts

两条服务器做同样的操作。
修改hosts文件：
```sh
sudo vi /etc/hosts
```

添加以下内容：
```
192.168.241.140 Hadoop-Master
192.168.241.141 Hadoop-Slave
```

测试：
```sh
fwj@Hadoop-Master:~$ ping Hadoop-Slave
fwj@Hadoop-Slave:~$ ping Hadoop-Master
```

#### 关闭防火墙

两条服务器做同样的操作。
```sh
sudo ufw disable
```

#### 安装JDK

1.下载JDK

下载地址：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html，这里选择jdk-8u181-linux-x64.tar.gz。使用rz命令上传文件到Hadoop-Master。

```sh
fwj@Hadoop-Master:~$ tar -xzvf jdk-8u181-linux-x64.tar.gz
# 两台都操作
sudo mkdir /usr/java/
fwj@Hadoop-Master:~$ sudo mv jdk1.8.0_181 /usr/java/
```

复制到Hadoop-Slave：
```sh
scp -r jdk1.8.0_181 fwj@Hadoop-Slave:~/
```

在Hadoop-Slave上操作：
```sh
sudo mv jdk1.8.0_181 /usr/java/
```

2.配置环境变量

修改文件，
```sh
sudo /etc/profile
```
添加以下内容：
```
JAVA_HOME=/usr/java/jdk1.8.0_181
PATH=$PATH:$JAVA_HOME/bin
```
使配置生效：
```sh
source /etc/profile
```

测试：
```sh
# 输入java命令
java -version
```

#### Hadoop安装

1.下载Hadoop

```
fwj@Hadoop-Master:~$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/stable/hadoop-2.9.1.tar.gz
```

2.解压

```sh
fwj@Hadoop-Master:~$ tar -zxvf hadoop-2.9.1.tar.gz
```

3.修改配置

- 配置环境变量`hadoop-env.sh`

```sh
fwj@Hadoop-Master:~$ cd hadoop-2.9.1/etc/hadoop/
fwj@Hadoop-Master:~$ vi hadoop-env.sh
```
修改JAVA_HOME为`JAVA_HOME=/usr/java/jdk1.8.0_181`

- 配置环境变量`yarn-env.sh`

```sh
fwj@Hadoop-Master:~$ vi hadoop-env.sh
```
修改JAVA_HOME为`JAVA_HOME=/usr/java/jdk1.8.0_181`


- 配置核心组件`core-site.xml`

```sh
fwj@Hadoop-Master:~$ vi core-site.xml
```
配置如下：
```xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop-master:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/home/fwj/hadoopdata</value>
  </property>
</configuration>
```

- 配置文件系统`hdfs-site.xml`

```sh
fwj@Hadoop-Master:~$ vi hdfs-site.xml
```
配置如下：
```xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
</configuration>
```

- 配置计算框架`mapred-site.xml`

```sh
fwj@Hadoop-Master:~$ vi mapred-site.xml
```
配置如下：
```xml
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

- 配置文件系统`yarn-site.xml`

```sh
fwj@Hadoop-Master:~$ vi yarn-site.xml
```
配置如下：
```xml
<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>hadoop-master:18040</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>hadoop-master:18030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>hadoop-master:18025</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>hadoop-master:18041</value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>hadoop-master:18088</value>
  </property>
</configuration>
```

- 配置从节点`slaves`

```sh
fwj@Hadoop-Master:~$ vi slaves
```
localhost改成 `hadoop-slave`

- 复制到从节点

```sh
fwj@Hadoop-Master:~$ cd

fwj@Hadoop-Master:~$ scp -r hadoop-2.9.1 fwj@hadoop-slave:~/
```

#### 启动Hadoop集群

1.创建数据目录

主从都创建目录：
```sh
mkdir /home/fwj/hadoopdata
```

2.格式化文件系统

主节点上操作：
```sh
fwj@Hadoop-Master:~$ hadoop-2.9.1/bin/hdfs namenode -format
```

3.启动

主节点：
```sh
hadoop-2.9.1/sbin/hadoop-daemon.sh start namenode
hadoop-2.9.1/sbin/yarn-daemon.sh start resourcemanager
```

从节点：
```sh
hadoop-2.9.1/sbin/hadoop-daemon.sh start datanode
hadoop-2.9.1/sbin/yarn-daemon.sh start nodemanager
```

#### 验证

1.浏览器访问：`http://192.168.241.140:18088`

![img](../../../../img/in-post/post_bigdata/7.png)

2.输入jps

![img](../../../../img/in-post/post_bigdata/9.png)
![img](../../../../img/in-post/post_bigdata/8.png)

3.浏览器访问：`http://192.168.241.140:50070`

![img](../../../../img/in-post/post_bigdata/10.png)