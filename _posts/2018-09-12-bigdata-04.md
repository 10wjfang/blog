---
layout: post
title: 【分析】用Hive搭建数据仓库（五）
date: 2018-9-12 21:31:17
catalog: true
tags:
    - 大数据
    - Hadoop
    - Hive
---

## Hive简介

Hive是一个在Hadoop中用来处理结构化数据**数据仓库基础工具**。它是建立在Hadoop之上的数据仓库基础架构，总归为大数据，并使得查询和分析方便。

Hive是由Facebook开发，后来由Apache软件基金会开发，并作为进一步将它作为名义下Apache Hive为一个开源项目。

#### Hive的特点

- 它存储架构在一个数据库中并处理数据到HDFS。
- 它是专为OLAP设计。
- 它提供SQL类型语言查询叫HiveQL或HQL。
- 它是熟知，快速，可扩展和可扩展的。

## Hive架构

Hive利用HDFS存储数据，利用MapReduce查询数据。

![img](../../../../img/in-post/post_bigdata/14.jpg)

|单元名称|操作|
|:--|:--|
|用户接口/界面|Hive是一个数据仓库基础工具软件，可以创建用户和HDFS之间互动。用户界面，Hive支持是Hive的Web UI，Hive命令行，HiveHD洞察（在Windows服务器）。|
|元存储|Hive选择各自的数据库服务器，用以储存表，数据库，列模式或元数据表，它们的数据类型和HDFS映射。默认使用内嵌的derby数据库作为存储引擎，但一次只能打开一个会话，可使用MySQL最为Hive的外置存储引擎。|
|HiveQL处理引擎|HiveQL类似于SQL的查询上Metastore模式信息。这是传统的方式进行MapReduce程序的替代品之一。相反，使用Java编写的MapReduce程序，可以编写为MapReduce工作，并处理它的查询。|
|执行引擎|HiveQL处理引擎和MapReduce的结合部分是由Hive执行引擎。执行引擎处理查询并产生结果和MapReduce的结果一样。它采用MapReduce方法。|
|HDFS 或 HBASE|Hadoop的分布式文件系统或者HBASE数据存储技术是用于将数据存储到文件系统。|

## Hive安装部署

Hive版本：`2.3.3`

MySQL地址：`192.168.241.131`

- **安装条件：**
  - Hive安装在Hadoop集群上，并Hadoop集群已启动
  - MySQL已安装并已启动
- **下载并安装Hive：**
  - 从Hive官网`https://mirrors.tuna.tsinghua.edu.cn/apache/hive/stable-2/`下载Hive
  - 通过`rz`命令将Hive安装包`apache-hive-2.3.3-bin.tar.gz`上传到/home/fwj/目录
  - 解压安装 `tar -zxvf apache-hive-2.3.3-bin.tar.gz`
  - 配置Hive环境变量
    - `export HIVE_HOME=/home/fwj/apache-hive-2.3.3-bin`
    - `export PATH=$HIVE_HOME/bin:$PATH`
- **配置MySQL：**
  - 下载MySQL驱动：`http://www.java2s.com/Code/Jar/m/Downloadmysqlconnectorjar.htm`
  - 上传`mysql-connector-java-5.1.21.jar`的驱动到HIVE_HOME/lib目录下
  - 登录MySQL，创建数据库hive：`create database hive`
  - 配置Hive的hive-site.xml

hive-site.xml文件：
```xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://192.168.241.131/hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123456</value>
    </property>
</configuration>
```

- **初始化Hive：**
  - 从 Hive 2.1 版本开始, 我们需要先运行 schematool 命令来执行初始化操作：`schematool -dbType mysql -initSchema`
  - 输入`hive`命令进入，`exit;`可退出

初始化Hive后，在MySQL可以看到生成的表：

![img](../../../../img/in-post/post_bigdata/13.png)


## 使用Hive搭建数据仓库

1、创建数据仓库

```sql
hive> create database if not exists school;
```

2、创建表

```sql
hive> create external table if not exists school.student(stuid INT,stuname STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE
LOCATION '/school/';
```

- external：创建一个外部表，在建表的同时指定一个指向实际数据的路径（LOCATION）

创建表成功后，可以在HDFS看到school目录：
![img](../../../../img/in-post/post_bigdata/14.png)

3、测试文件

将students.txt上传到HDFS的school目录下：

```sh
hadoop fs -put students.txt /school/
```
students.txt：
```txt
1231    xiaoming
2312    xiaohong
1343    wuming
3423    xiaoming
3124    fej
4536    fwa
6744    fej
2314    fwj
3424    xiaoming
```

4、查询所有数据

```sql
hive> use school;
hive> select * from student;
```
![img](../../../../img/in-post/post_bigdata/15.png)

4、统计同名

```sql
hive> use school;
hive> select stuname,count(*) from student group by stuname;
```
这时会启动一个作业，执行MapReduce过程。
![img](../../../../img/in-post/post_bigdata/16.png)


## 参考

[Hive官方地址](https://hive.apache.org/)

[hive2.1.1 部署安装](https://blog.csdn.net/u013310025/article/details/70306421)